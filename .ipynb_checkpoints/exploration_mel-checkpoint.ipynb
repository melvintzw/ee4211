{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%pprint off\n",
    "#plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"ticks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv('data/dataport-export_gas_oct2015-mar2016.csv')\n",
    "len(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.set_index(pd.to_datetime(df_all['localminute']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all = df_all.drop(columns='localminute')\n",
    "display(df_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df_all.groupby('dataid')\n",
    "keys = groups.groups.keys()  # keys: an iterable of dataids or meter ids\n",
    "\n",
    "# check if each group (grouped by meter id) is sorted in ascending order by datetime.\n",
    "# for key in keys:\n",
    "#     df_i = groups.get_group(key)\n",
    "#     print(df_i.index.is_monotonic_increasing)\n",
    "# each group is already sorted in ascending order by datetime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check meterids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_list = list(keys)\n",
    "print(keys_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print full-length (6 mth) plot by meterid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for key in keys_list:    \n",
    "#     df_i = groups.get_group(key)\n",
    "#     df_i.drop(columns='dataid').plot(figsize=(15,4), title=str(f'meter {key}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 3134\n",
    "df_i = groups.get_group(key).drop(columns='dataid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select data by datetime period. e.g. 1 month. i.e. Zoom in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoom(df, start_date, end_date):\n",
    "    # pre-condition: df is indexed by datetime.\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    end_date = pd.to_datetime(end_date)\n",
    "    mask = (df.index >= start_date) & (df.index <= end_date)\n",
    "\n",
    "    new_df = df.iloc[mask]\n",
    "    return new_df\n",
    "    \n",
    "df_i_bymonth = zoom(df_i, '2015-12-01', '2016-01-01')\n",
    "df_i_bymonth.plot(figsize=(15,4), title=str(f'meter {key}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample with hourly frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i_bymonth_resampled = df_i_bymonth.resample('H').mean().ffill()\n",
    "df_i_bymonth_resampled.plot(figsize=(15,4), title=str(f'meter {key}'))\n",
    "display(len(df_i_bymonth_resampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate and plot december's hourly-resampled data for each suspicious meter (spiking values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "suspicious_meters_list = [1185, 1556, 2335, 2449, 3134, 3544, 4447, 4514, \\\n",
    "                          5129, 5403,6836, 7030, 7117, 8156, 9134, 9639, 9982]\n",
    "\n",
    "# for meter in suspicious_meters_list:\n",
    "#     df_i = groups.get_group(meter)\n",
    "#     df_i_bymonth = zoom(df_i, '2015-12-01', '2016-01-01').drop(columns='dataid')\n",
    "#     df_i_bymonth_resampled = df_i_bymonth.resample('H').mean().ffill()\n",
    "#     df_i_bymonth_resampled.plot(figsize=(15,4), title=str(f'meter {meter}, {len(df_i_bymonth_resampled)} samples'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clearly see that there is some obvious malfunctioning happening within 7-14 Dec 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zoom in deeper within the time period (e.g. one day/24h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i_byday = zoom(df_i_bymonth_resampled, '2015-12-11', '2015-12-12')\n",
    "df_i_byday.plot(figsize=(15,4), title=str(f'meter {key}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for i in range(7):\n",
    "#     start_date = f'2015-12-{8+i}'\n",
    "#     end_date = f'2015-12-{9+i}'\n",
    "#     df_i_byday = zoom(df_i_bymonth_resampled, start_date, end_date)\n",
    "#     df_i_byday.plot(figsize=(15,4), title=str(f'meter {key}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "less500_list = [4874, 6101, 9620, 7566, 5545, 2814, 2946, 2755,\\\n",
    "                9160, 2645, 6685, 1403, 8703, 9600, 3036, 5658]\n",
    "\n",
    "def get_month_counts(df_i):\n",
    "    # get count of samples per month\n",
    "    df_i_resample_monthly_count = df_i.resample('M').count().rename(columns={'meter_value': 'count'})  \n",
    "    return df_i_resample_monthly_count\n",
    "\n",
    "for meter in less500_list:\n",
    "    df_i = groups.get_group(meter)\n",
    "    df_i_counts = get_month_counts(df_i)\n",
    "    display(df_i_counts.head(6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_list = []\n",
    "for key in keys_list:\n",
    "    df_i = groups.get_group(key)\n",
    "    count_list.append(len(df_i.index))\n",
    "    \n",
    "less2000_mask = np.asarray(count_list) < 2000\n",
    "display(less2000_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "less2000_list = []\n",
    "for i in range(len(less2000_mask)):\n",
    "    if less2000_mask[i] == True:\n",
    "        less2000_list.append(keys_list[i])\n",
    "\n",
    "display(less2000_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for meter in less2000_list:\n",
    "#     df_i = groups.get_group(meter).drop(columns='dataid')\n",
    "#     df_i_resample_monthly_count = df_i.resample('M').count()  # get count of samples per month\n",
    "    \n",
    "#     display(f'avg sample per month: {len(df_i)/len(df_i_resample_monthly_count)}',\\\n",
    "#             f'nmonths={len(df_i_resample_monthly_count)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample data hourly, taking last value in the hour as new value.\n",
    "For each meter:\n",
    "- Visualise 6month usage\n",
    "- Visualise 1month usage\n",
    "- Visualise 1day usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Resample by taking last cumulative reading for each hour.\n",
    "\n",
    "# key = keys_list[4]\n",
    "# df_i = groups.get_group(key).drop(columns='dataid')\n",
    "# df_i.plot(figsize=(15,4), title=str(f'meter {key}'))\n",
    "\n",
    "# # resample hourly using last reading for each hour, forward-filling any missing values\n",
    "# df_i_resample_hourly = df_i.resample('H').last().ffill()\n",
    "# df_i_resample_hourly.plot(figsize=(15,4), title=str(f'meter {key}'))\n",
    "\n",
    "# display(f'total samples: {len(df_i)}')\n",
    "# display(f'no. of hours: {len(df_i_resample_hourly)}')\n",
    "# first_date = df_i.index.values[0] \n",
    "# last_date = df_i.index.values[-1]\n",
    "# display(f'first date: {first_date}')\n",
    "# display(f'last date: {last_date}')\n",
    "# display(df_i_resample_hourly.tail())\n",
    "\n",
    "# # zoom in to particular month\n",
    "# df_i_month = zoom(df_i_resample_hourly, '2016-01-01', '2016-02-01')\n",
    "# df_i_month.plot(figsize=(15,4), title=str(f'meter {key}'))\n",
    "\n",
    "# # zoom in to particular day\n",
    "# df_i_day = zoom(df_i_month, '2016-01-02', '2016-01-03')\n",
    "# df_i_day.plot(figsize=(15,4), title=str(f'meter {key}'))\n",
    "\n",
    "# # find hour on hour change, i.e. marginal hourly usage\n",
    "# # this is useful to notice hourly consumption patterns\n",
    "# df_i_day.diff().plot(figsize=(15,4), title=str(f'meter {key}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_mal_data(df):\n",
    "    # this method finds the start datetime and end datetime of the malfunctioning period and returns a new df without data\n",
    "    # from that period. NOTE that a new column 'marginal_change' is added to the df.\n",
    "    \n",
    "    # from visualising the data, we can arbitrarily define a spike as a marginal difference of > 2000 cubic metres\n",
    "    # we have defined malfunction as a marginal increase > 2000\n",
    "    # and a marginal increase < -2000.\n",
    "    threshold = 2000\n",
    "    df['marginal_change'] = df['meter_value'].diff()\n",
    "    \n",
    "    flagged_dates = df[df.marginal_change > threshold].index\n",
    "    flagged_dates = flagged_dates.append(df[df.marginal_change < -1*threshold].index)\n",
    "    \n",
    "    if len(flagged_dates) > 0:\n",
    "        start = flagged_dates[0]\n",
    "        end = flagged_dates[-1]    \n",
    "        mask = (df.index >= start) & (df.index <= end)\n",
    "        return df.loc[~mask]\n",
    "    else:\n",
    "        return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 1185\n",
    "df_i = groups.get_group(key).drop(columns='dataid')\n",
    "display(len(df_i))\n",
    "\n",
    "df_i_clean = remove_mal_data(df_i)\n",
    "display(len(df_i_clean))\n",
    "\n",
    "df_i_clean.meter_value.plot(figsize=(15,4), title=str(f'meter {key}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_negative_marginal(df):\n",
    "    # remove data points where the marginal change (from prev value) is negative.\n",
    "    return df.loc[df.marginal_change >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, coeff=1.5):\n",
    "    # remove outliers using *IQR rule.\n",
    "    tmp_df = df.loc[df.marginal_change > 1]\n",
    "    Q1 = tmp_df['marginal_change'].quantile(0.25)\n",
    "    Q3 = tmp_df['marginal_change'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    #print(f'{Q1, Q3, IQR}')\n",
    "    \n",
    "    # Filtering Values between Q1-coeff*IQR and Q3+coeff*IQR\n",
    "    return df.query('(@Q1 - @coeff * @IQR) <= marginal_change <= (@Q3 + @coeff * @IQR)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(df_i_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i_filtered = remove_outliers(df_i_clean)\n",
    "display(len(df_i_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i_filtered['meter_value'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply cleaning, resampling, and 1.5IQR-filtering to entire 6 month period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in suspicious_meters_list:\n",
    "    df_i = groups.get_group(key).drop(columns='dataid')\n",
    "    display(len(df_i))\n",
    "\n",
    "    \n",
    "    # first, clean data by removing obvious dirt\n",
    "    df_i_clean = remove_mal_data(df_i)\n",
    "    df_i_clean = remove_negative_marginal(df_i_clean)\n",
    "    \n",
    "    # next, resample data by hour.\n",
    "    df_i_resampled = df_i_clean.drop(columns='marginal_change').resample('H').mean().ffill()\n",
    "    display(df_i_resampled.head())\n",
    "    \n",
    "    # then, obtain new marginal changes.\n",
    "    df_i_resampled['marginal_change'] = df_i_resampled['meter_value'].diff()\n",
    "    display(df_i_resampled.head())\n",
    "    df_i_resampled['marginal_change'].plot(figsize=(15,4), title=str(f'meter {key}'))\n",
    "    display(len(df_i_resampled))\n",
    "    \n",
    "    # finally, filter by the 1.5IQR rule on marginal_change.\n",
    "    df_i_filtered = remove_outliers(df_i_resampled)\n",
    "    display(len(df_i_filtered))\n",
    "\n",
    "    df_i_filtered['marginal_change'].plot(figsize=(15,4), title=str(f'meter {key}'))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above code snippet and output shows that IQR-filtering should not be applied to the entire 6 months, because of seasonal changes in household use of gas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IQR-filtering seems more reasonable after constraining the time period to one month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting test\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15,6))\n",
    "\n",
    "df_i.plot(ax=axes[0,0], title='hi')\n",
    "df_i.plot(ax=axes[0,1], title='hi')\n",
    "df_i.plot(ax=axes[1,0], title='hi')\n",
    "axes[0,0].clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i.plot(ax=axes[0,0], title='hi')\n",
    "df_i.plot(ax=axes[0,1], title='hi')\n",
    "df_i.plot(ax=axes[1,0], title='hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15,6))  \n",
    "# seems like I must call this again everytime i plot in a new cell?\n",
    "# otherwise, no plot is shown when I call plot().\n",
    "\n",
    "df_i.plot(ax=axes[0,0], title='hi')\n",
    "df_i.plot(ax=axes[0,1], title='hi')\n",
    "df_i.plot(ax=axes[1,0], title='hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# zoom into 1 month\n",
    "key = 1185\n",
    "df_i = groups.get_group(key).drop(columns='dataid')\n",
    "df_i_1mth = zoom(df_i, '2016-01-01', '2016-02-01')\n",
    "\n",
    "def clean_resample_filter2(key, df_i, showplot=False):\n",
    "    # v2 of this method uses/tests multiple plots\n",
    "    # pre-condition, df_i has has numerical data to plot.\n",
    "    \n",
    "    # first, clean data by removing obvious dirt\n",
    "    df_i_clean = remove_mal_data(df_i_1mth)\n",
    "    df_i_clean = remove_negative_marginal(df_i_clean)\n",
    "\n",
    "    # next, resample data by hour.\n",
    "    df_i_resampled = df_i_clean.drop(columns='marginal_change').resample('H').mean().ffill()\n",
    "    #display(df_i_resampled.head())\n",
    "\n",
    "    # then, obtain new marginal changes.\n",
    "    df_i_resampled['marginal_change'] = df_i_resampled['meter_value'].diff()\n",
    "    \n",
    "    # finally, filter by the IQR rule on marginal_change.\n",
    "    # 1.5IQR filter\n",
    "    df_i_filtered15 = remove_outliers(df_i_resampled, 1.5)\n",
    "    \n",
    "    if showplot:\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,3))\n",
    "        # plot\n",
    "        df_i_resampled['marginal_change'].plot(ax=axes[0])\n",
    "        if len(df_i_filtered15) > 0:\n",
    "            df_i_filtered15['marginal_change'].plot(ax=axes[0], \\\n",
    "                                                title=str(f'meter {key}, 1.5IQR, bef:{len(df_i_resampled)}, aft:{len(df_i_filtered15)}'))\n",
    "        # 3.0IQR filter\n",
    "        df_i_filtered30 = remove_outliers(df_i_resampled, 3.0)\n",
    "\n",
    "        # plot\n",
    "        df_i_resampled['marginal_change'].plot(ax=axes[1])\n",
    "        if len(df_i_filtered30) > 0:\n",
    "            df_i_filtered30['marginal_change'].plot(ax=axes[1], \\\n",
    "                                                    title=str(f'meter {key}, 3.0 IQR, bef:{len(df_i_resampled)}, aft:{len(df_i_filtered30)}'))\n",
    "    \n",
    "    return df_i_filtered15\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find meters for which readings are sparse in a particular month;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '2016-01-01'\n",
    "end = '2016-02-01'\n",
    "\n",
    "lack_data_for_monthx = [] \n",
    "for key in keys_list:\n",
    "    df_i = groups.get_group(key).drop(columns='dataid')\n",
    "    df_i_1mth = zoom(df_i, start, end)\n",
    "    \n",
    "    if len(df_i_1mth) > 1:\n",
    "        df_i_counts = get_month_counts(df_i_1mth)\n",
    "        if df_i_counts['count'].values[0] < 3:\n",
    "            lack_data_for_monthx.append(key)\n",
    "    else:\n",
    "        lack_data_for_monthx.append(key)\n",
    "print(lack_data_for_monthx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# malfunctioning and sparse readings\n",
    "to_remove = [1185, 1556, 2335, 2449, 3134, 3544, 4447, 4514,\\\n",
    "             5129, 5403, 6836, 7030, 7117, 8156, 9134, 9639, 9982]\n",
    "\n",
    "to_remove.extend(lack_data_for_monthx)\n",
    "\n",
    "display(to_remove, len(to_remove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# to_keep = [elem for elem in keys_list if elem not in to_remove]\n",
    "\n",
    "# for key in to_keep:\n",
    "#     df_i = groups.get_group(key).drop(columns='dataid')\n",
    "#     df_i_1mth = zoom(df_i, start, end)   \n",
    "#     clean_resample_filter2(key, df_i_1mth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### integrate data prep section with the correlation section (q1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select month\n",
    "start = '2015-01-01'\n",
    "end = '2016-02-01'\n",
    "\n",
    "# find meters for which there is a lack of data in that month\n",
    "lack_data_for_monthx = [] \n",
    "for key in keys_list:\n",
    "    df_i = groups.get_group(key).drop(columns='dataid')\n",
    "    df_i_1mth = zoom(df_i, start, end)\n",
    "    \n",
    "    if len(df_i_1mth) > 1:\n",
    "        df_i_counts = get_month_counts(df_i_1mth)\n",
    "        if df_i_counts['count'].values[0] < 3:\n",
    "            lack_data_for_monthx.append(key)\n",
    "    else:\n",
    "        lack_data_for_monthx.append(key)\n",
    "print(lack_data_for_monthx)\n",
    "\n",
    "# malfunctioning meters and meters with sparse readings\n",
    "to_remove = [1185, 1556, 2335, 2449, 3134, 3544, 4447, 4514,\\\n",
    "             5129, 5403, 6836, 7030, 7117, 8156, 9134, 9639, 9982]\n",
    "\n",
    "to_remove.extend(lack_data_for_monthx)\n",
    "\n",
    "display(to_remove, len(to_remove))\n",
    "\n",
    "# meters to use for computation\n",
    "to_keep = [elem for elem in keys_list if elem not in to_remove]\n",
    "\n",
    "df_all = pd.DataFrame()\n",
    "for key in [114]:\n",
    "    df_i = groups.get_group(key).drop(columns='dataid')\n",
    "    df_i_1mth = zoom(df_i, start, end)   \n",
    "    df_i_filtered = clean_resample_filter2(key, df_i_1mth).rename(columns={'marginal_change': f'marginal {key}'})\n",
    "    df_all = pd.concat([df_all, df_i_filtered[f'marginal {key}']], axis=1)\n",
    "\n",
    "display(df_all.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean, resample, filter all valid meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame()\n",
    "for key in to_keep:\n",
    "    df_i = groups.get_group(key).drop(columns='dataid')\n",
    "    df_i_1mth = zoom(df_i, start, end)   \n",
    "    df_i_filtered = clean_resample_filter2(key, df_i_1mth).rename(columns={'marginal_change': f'marginal_{key}'})\n",
    "    df_all = pd.concat([df_all, df_i_filtered[f'marginal_{key}']], axis=1)\n",
    "           \n",
    "display(df_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_all.isna())\n",
    "df_all_nonan = df_all.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_all_nonan.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find correlations between households."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr_month = df_all_nonan.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = '{}:00'\n",
    "new_dict = dict()\n",
    "\n",
    "for i in range(0,24):\n",
    "    datatemp = pd.DataFrame(df_all_nonan.between_time(string.format(i),string.format(i)))\n",
    "    new_dict[i] = datatemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_dict[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_total = pd.DataFrame()\n",
    "for hour in range(24):    \n",
    "    # generate corr matrix\n",
    "    corr_matrix = new_dict[hour].corr().fillna(0)\n",
    "    #display(i, isnan, corr_matrix)\n",
    "    \n",
    "    df_hour = pd.DataFrame(columns=['r', 'id'])\n",
    "    # find top 5 positive correlations per meterid\n",
    "    for meterid in to_keep:    \n",
    "        df_corr_sorted = corr_matrix[f'marginal_{meterid}'].sort_values(ascending=False)\n",
    "        sr_top5 = df_corr_sorted.iloc[1:6]\n",
    "        df_top5 = sr_top5.to_frame()\n",
    "        df_top5 = df_top5.rename(columns={f'marginal_{meterid}': 'r'})\n",
    "\n",
    "        data = [meterid for i in range(5)]\n",
    "        df_top5 = df_top5.assign(id=data)\n",
    "        #display(df_top5)\n",
    "\n",
    "        df_hour = df_hour.append(df_top5)\n",
    "    #display(df_hour)\n",
    "    df_hour.to_csv(f'report/{hour}_corr.csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr_month\n",
    "\n",
    "df_hour = pd.DataFrame(columns=['r', 'id'])\n",
    "for meterid in to_keep:    \n",
    "    df_corr_sorted = df_corr_month[f'marginal_{meterid}'].sort_values(ascending=False)\n",
    "    sr_top5 = df_corr_sorted.iloc[1:6]\n",
    "    df_top5 = sr_top5.to_frame()\n",
    "    df_top5 = df_top5.rename(columns={f'marginal_{meterid}': 'r'})\n",
    "\n",
    "    data = [meterid for i in range(5)]\n",
    "    df_top5 = df_top5.assign(id=data)\n",
    "    #display(df_top5)\n",
    "\n",
    "    df_hour = df_hour.append(df_top5)\n",
    "    \n",
    "display(df_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hour.to_csv('report/corr_month.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
