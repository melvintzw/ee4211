{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set_style(\"ticks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dataframes by meterids and obtain list of meterids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35, 44, 77, 94, 114, 187, 222, 252, 370, 483, 484, 661, 739, 744, 871, 1042, 1086, 1103, 1185, 1283, 1403, 1415, 1507, 1556, 1589, 1619, 1697, 1714, 1718, 1790, 1791, 1792, 1800, 1801, 2018, 2034, 2072, 2094, 2129, 2233, 2335, 2378, 2449, 2461, 2470, 2575, 2638, 2645, 2755, 2814, 2818, 2945, 2946, 2965, 2980, 3036, 3039, 3134, 3310, 3367, 3527, 3544, 3577, 3635, 3723, 3778, 3849, 3893, 3918, 4029, 4031, 4193, 4228, 4296, 4352, 4356, 4373, 4421, 4447, 4514, 4671, 4732, 4767, 4874, 4998, 5129, 5131, 5193, 5275, 5317, 5395, 5403, 5439, 5484, 5545, 5636, 5658, 5785, 5810, 5814, 5892, 5972, 6101, 6412, 6505, 6578, 6673, 6685, 6830, 6836, 6863, 6910, 7016, 7017, 7030, 7117, 7287, 7429, 7460, 7566, 7674, 7682, 7739, 7741, 7794, 7900, 7919, 7965, 7989, 8059, 8084, 8086, 8155, 8156, 8244, 8386, 8467, 8703, 8829, 8890, 8967, 9052, 9121, 9134, 9160, 9278, 9295, 9474, 9600, 9620, 9631, 9639, 9729, 9766, 9849, 9956, 9982]\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.read_csv('data/dataport-export_gas_oct2015-mar2016.csv')\n",
    "df_all = df_all.set_index(pd.to_datetime(df_all['localminute']))\n",
    "df_all = df_all.drop(columns='localminute')\n",
    "groups = df_all.groupby('dataid')\n",
    "keys = groups.groups.keys()  # keys: an iterable of dataids or meter ids\n",
    "keys_list = list(keys)\n",
    "print(keys_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 35\n",
    "df_i = groups.get_group(key).drop(columns='dataid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoom(df, start_date, end_date):\n",
    "    # returns a df whose rows are within a particular time period. \n",
    "    # pre-condition: df is indexed by datetime.\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    end_date = pd.to_datetime(end_date)\n",
    "    mask = (df.index >= start_date) & (df.index <= end_date)\n",
    "\n",
    "    new_df = df.iloc[mask]\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot compare type 'Timestamp' with type 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-8c2a7f7ee613>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# example for zoom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_i_1mth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzoom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'2016-01-01'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'2016-02-01'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-ee02fe8d1030>\u001b[0m in \u001b[0;36mzoom\u001b[1;34m(df, start_date, end_date)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mstart_date\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mend_date\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mend_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mnew_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mcmp_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;31m# technically we could support bool dtyped Index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\tslibs\\timestamps.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.timestamps._Timestamp.__richcmp__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot compare type 'Timestamp' with type 'int'"
     ]
    }
   ],
   "source": [
    "# example for zoom\n",
    "df_i_1mth = zoom(df_i, '2016-01-01', '2016-02-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1 (optional part)\n",
    "def remove_mal_data(df):\n",
    "    # this method finds the start datetime and end datetime of the malfunctioning period and returns a new df without data\n",
    "    # from that period. i.e. the entire chunk of data from the faulty period is dropped.\n",
    "    # NOTE that a new column 'marginal_change' is added to the df.\n",
    "    # df: pandas dataframe. contains data from one meterid. contains a column 'meter_value'.\n",
    "    \n",
    "    # from visualising the data, we can arbitrarily define a spike as a marginal difference of > 2000 cubic metres\n",
    "    # we have defined malfunction as a marginal change > 2000\n",
    "    # and a marginal change < -2000.\n",
    "    threshold = 2000\n",
    "    df['marginal_change'] = df['meter_value'].diff()\n",
    "    \n",
    "    flagged_dates = df[df.marginal_change > threshold].index\n",
    "    flagged_dates = flagged_dates.append(df[df.marginal_change < -1*threshold].index)\n",
    "    \n",
    "    if len(flagged_dates) > 0:\n",
    "        start = flagged_dates[0]\n",
    "        end = flagged_dates[-1]    \n",
    "        mask = (df.index >= start) & (df.index <= end)\n",
    "        return df.loc[~mask]\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2. exclude meters with low sampling frequency\n",
    "\n",
    "# list of meters visually inspected and identified to be malfunctioning \n",
    "# based on spikes or irregularities seen on the plot.\n",
    "to_remove = [1185, 1556, 2335, 2449, 3134, 3544, 4447, 4514,\\\n",
    "             5129, 5403, 6836, 7030, 7117, 8156, 9134, 9639, 9982]\n",
    "\n",
    "low_samplefreq = [1874, 2645, 4671, 5545, 6101, 9620]\n",
    "\n",
    "to_remove.extend(low_samplefreq) \n",
    "\n",
    "display(to_remove, len(to_remove))\n",
    "\n",
    "# final meters to use for analysis\n",
    "to_keep = [elem for elem in keys_list if elem not in to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3. Change cumulative to marginal change.\n",
    "\n",
    "# we already have the 'marginal_change' column. \n",
    "# NOTE: the 'meter_value' or cumulative reading column is NO LONGER VALID after dropping any row.\n",
    "# the only exception is for the very first row which is the first cumulative reading.\n",
    "# if we are going to need cumulative readings again, we must construct them from this first cumulative reading and all\n",
    "# the new (remaining/cleaned) marginal changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4. remove marginal decrease.\n",
    "def remove_negative_marginal(df):\n",
    "    # remove data points where the marginal change (from prev value) is negative.\n",
    "    return df.loc[df['marginal_change'] >= 0]\n",
    "\n",
    "# same notes apply as in step 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 5. Get rate of increase from marginal changes (per second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 6. Mark anomalies from rate of increase with threshold = 0.166/s\n",
    "# step 7. Remove these anomalies\n",
    "# step 8. Resample hourly, finding the new hourly marginal reading. Construct cumulative readings as necessary.\n",
    "# step 9. visualise cleaned readings. confirm that results are as intended\n",
    "# step 10. save combined data into a new csv file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
